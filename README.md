## Main Data for the Competition

The legal corpus is provided in the file `alqac25_law.json`.  
Training data for Task 1 (Legal Document Retrieval) and Task 2 (Legal Question Answering) is available in `alqac25_train.json`.

## Additional Data for Task 1
The additional data for Task 1, which is sponsored by Zalo, is in the folder `additional_data/zalo`. It is optional to use this data to train your models.

## Restriction
In the spirit of fostering open research and reproducibility, participating teams are permitted to use any publicly available resources intended for the research community. This includes online legal databases such as vbpl.vn and open-weight large language models (LLMs) like LLaMA-3.

However, the following restrictions apply:
- The use of **closed or proprietary systems**—such as ChatGPT, GPT-4, Claude, Gemini, or any other non-open models—is strictly prohibited.
- To ensure fairness and accessibility, only **open-weight models with fewer than 10 billion parameters** are allowed. This encourages efficient, resource-conscious approaches and levels the playing field for teams with limited computational resources.
- While **online legal databases** are permitted, the use of **externally annotated datasets** specifically created for **legal question answering** or **legal entailment** (e.g., labeled QA pairs or entailment examples) is **not allowed**.

Any results obtained in violation of these rules will be disregarded in the final team ranking.